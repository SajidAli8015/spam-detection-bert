{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ec7a83",
   "metadata": {},
   "source": [
    "### Fine-tuning BERT SMS Model on Email Spam Dataset\n",
    "\n",
    "This notebook loads a pre-trained DistilBERT model trained on SMS spam data and fine-tunes it on a phishing email dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50175e6f",
   "metadata": {},
   "source": [
    "# ðŸ§¾ 1. Library Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e719b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Sajid\\email-spam-detection\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Ensure we use CPU only\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a128fa",
   "metadata": {},
   "source": [
    "# ðŸ§¾ 2. Load Pre-trained SMS Model from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c138736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your saved model\n",
    "model_path = \"D:/Sajid/email-spam-detection/models/bert-sms-spam/version_20250508_185703\"\n",
    "\n",
    "# Load tokenizer and model from disk\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c70f7",
   "metadata": {},
   "source": [
    "# ðŸ§¾ 3. Load and Preprocess Phishing Email Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60807f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_combined  label\n",
       "0  hpl nom may 25 2001 see attached file hplno 52...      0\n",
       "1  nom actual vols 24 th forwarded sabrae zajac h...      0\n",
       "2  enron actuals march 30 april 1 201 estimated a...      0\n",
       "3  hpl nom may 30 2001 see attached file hplno 53...      0\n",
       "4  hpl nom june 1 2001 see attached file hplno 60...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the phishing email dataset\n",
    "email_df = pd.read_csv(\"D:\\Sajid\\email-spam-detection\\data\\Phishing Email Dataset/phishing_email.csv\")\n",
    "\n",
    "email_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d35ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  hpl nom may 25 2001 see attached file hplno 52...      0\n",
       "1  nom actual vols 24 th forwarded sabrae zajac h...      0\n",
       "2  enron actuals march 30 april 1 201 estimated a...      0\n",
       "3  hpl nom may 30 2001 see attached file hplno 53...      0\n",
       "4  hpl nom june 1 2001 see attached file hplno 60...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the relevant columns and rename for consistency\n",
    "email_df = email_df[['text_combined', 'label']].dropna()\n",
    "email_df = email_df.rename(columns={'text_combined': 'text', 'label': 'label'})\n",
    "\n",
    "# Remove duplicate messages based on the cleaned text\n",
    "email_df = email_df.drop_duplicates(subset='text')\n",
    "\n",
    "email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051b633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text by removing URLs and special characters, and lowercasing\n",
    "def clean_email_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df['text'] = email_df['text'].apply(clean_email_text)\n",
    "\n",
    "# saving the copy of the complete data set\n",
    "email_df_full = email_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b413da",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 4. Randomly Sample Emails for Training + Validation\n",
    "- since using CPU so sampling a subset of data to speed up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save the original row indices so we can later use them if required\n",
    "original_indices_used = email_df.sample(n=3000, random_state=42).index\n",
    "\n",
    "# Now slice the actual training data\n",
    "email_df = email_df.loc[original_indices_used].reset_index(drop=True)\n",
    "\n",
    "#to check the dist of both classes in the sampled data\n",
    "email_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b271716c",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 5. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84112a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets with stratification to preserve label distribution\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    email_df['text'].tolist(),\n",
    "    email_df['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=email_df['label'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e175a",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 6. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019a3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into token IDs with padding and truncation to max_length\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a84fe",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 7. Wrap Tokenized Data in PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ad0419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class to use with HuggingFace Trainer\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EmailDataset(train_encodings, train_labels)\n",
    "val_dataset = EmailDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8cd11",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 8. Define TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68d4af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Sajid\\email-spam-detection\\venv\\lib\\site-packages\\transformers\\training_args.py:1595: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up the training configuration\n",
    "training_args = TrainingArguments(\n",
    "   # output_dir=\"outputs/bert_email_model\",         # Save directory\n",
    "    num_train_epochs=3,                             # Number of training epochs\n",
    "    per_device_train_batch_size=4,                  # Batch size for training\n",
    "    per_device_eval_batch_size=4,                   # Batch size for evaluation\n",
    "    gradient_accumulation_steps=2,\n",
    "    eval_strategy=\"epoch\",                   # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",                         # Save model after each epoch\n",
    "    logging_dir=\"logs\",                            # Logging directory\n",
    "    load_best_model_at_end=True,                    # Load best model by selected metric\n",
    "    metric_for_best_model=\"f1\",                    # Best model based on F1 score\n",
    "    greater_is_better=True,                         # Higher F1 is better\n",
    "    no_cuda=True                                    # Use CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22f69c",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 9. Define Custom Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cb9d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define how metrics will be computed during evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8084e6",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 10. Initialize Trainer and Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11a87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Trainer with model, args, data, and metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce3f63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 3:50:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332420</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.992248</td>\n",
       "      <td>0.839344</td>\n",
       "      <td>0.909414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.142995</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.952077</td>\n",
       "      <td>0.977049</td>\n",
       "      <td>0.964401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.122552</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973770</td>\n",
       "      <td>0.973770</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=0.17937433666653102, metrics={'train_runtime': 13840.9678, 'train_samples_per_second': 0.52, 'train_steps_per_second': 0.065, 'total_flos': 953765270323200.0, 'train_loss': 0.17937433666653102, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on email dataset\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611b273",
   "metadata": {},
   "source": [
    "## ðŸ§¾ 11. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bbade74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12255200743675232, 'eval_accuracy': 0.9733333333333334, 'eval_precision': 0.9737704918032787, 'eval_recall': 0.9737704918032787, 'eval_f1': 0.9737704918032787, 'eval_runtime': 203.7895, 'eval_samples_per_second': 2.944, 'eval_steps_per_second': 0.736, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model using built-in evaluate function\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13350ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.97      0.97       295\n",
      "        spam       0.97      0.97      0.97       305\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print detailed classification report using scikit-learn\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_true = val_labels\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"ham\", \"spam\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b998bfa",
   "metadata": {},
   "source": [
    "# ðŸ§¾ 12. Evaluate on Unseen  Emails / Test Data\n",
    "- testing data on randomly chosen 2000 rows (excluding 10000 rows used in training and model validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e291f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows NOT used in original 1000\n",
    "remaining_df = email_df_full.drop(index=original_indices_used)\n",
    "\n",
    "#Randomly sample 2000 rows from the remaining data\n",
    "test_df = remaining_df.sample(n=2000, random_state=7).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eced8e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Classification Report (on 2000 unseen emails):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     ham (0)       0.97      0.96      0.97       970\n",
      "    spam (1)       0.97      0.97      0.97      1030\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean and tokenize (reuse cleaning function if needed)\n",
    "test_df['text'] = test_df['text'].apply(clean_email_text)\n",
    "\n",
    "# Tokenize\n",
    "test_encodings = tokenizer(\n",
    "    test_df['text'].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# Wrap in PyTorch Dataset\n",
    "test_dataset = EmailDataset(test_encodings, test_df['label'].tolist())\n",
    "\n",
    "# Evaluate\n",
    "test_preds = trainer.predict(test_dataset)\n",
    "y_test_true = test_df['label'].tolist()\n",
    "y_test_pred = np.argmax(test_preds.predictions, axis=1)\n",
    "\n",
    "# Detailed classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nðŸ“Š Classification Report (on 2000 unseen emails):\")\n",
    "print(classification_report(y_test_true, y_test_pred, target_names=[\"ham (0)\", \"spam (1)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f931e",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df624bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to: D:/Sajid/email-spam-detection/models/bert-email-spam\n"
     ]
    }
   ],
   "source": [
    "# Save Fine-tuned Model to specified directory\n",
    "save_path = \"D:/Sajid/email-spam-detection/models/bert-email-spam\"\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a198f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (email-spam-env)",
   "language": "python",
   "name": "email-spam-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
